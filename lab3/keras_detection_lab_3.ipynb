{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1\n",
    "firstly, a list which contains weights is given. You need to load the weight into the model correctly. Then test the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weights_list is the parameter sets of the networks\n",
    "\n",
    "It's structure is like:\n",
    "[\n",
    "[],\n",
    "[layer a's weights, layer a's bias,...],\n",
    "[layer b's weights]\n",
    "]\n",
    "'''\n",
    "import pickle\n",
    "with open ('params_sets', 'rb') as fp:\n",
    "    weights_list = pickle.load(fp)\n",
    "    \n",
    "def getParams():\n",
    "    with open('params_sets', 'rb') as fp:\n",
    "        weights_list = pickle.load(fp)\n",
    "    weights_list = [np.array(w) for w in weights_list]\n",
    "    return weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is the model for the testing part\n",
    "names = ['dw1', 'bn1', 'conv1', 'bn2', 'dw2', 'bn3', 'conv2', 'bn4', 'dw3', 'bn5', 'dw4', 'bn6', 'conv3', 'bn7',\n",
    "        'dw5', 'bn8', 'dw6', 'bn9', 'conv4', 'bn10', 'conv5']\n",
    "def model():\n",
    "    rv = tf.keras.models.Sequential(\n",
    "        [\n",
    "        #first dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(48,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #second dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(96,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #third dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(192,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #fourth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(384,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #fifth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(512,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #output\n",
    "        layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        ]\n",
    "    )\n",
    "    rv.trainable = False\n",
    "    return rv\n",
    "\n",
    "def model_no_bn():\n",
    "    rv = tf.keras.models.Sequential(\n",
    "        [\n",
    "        #first dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(48,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #second dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(96,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #third dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(192,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #fourth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(384,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #fifth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(512,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #output\n",
    "        layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        ]\n",
    "    )\n",
    "    rv.trainable = False\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write down the code to absorb bn layer into conv layer and maintain the same output as the original model. (please refer to HW2 Q4)\n",
    "'''\n",
    "def create_no_bn_weights(in_weights):\n",
    "    out_weights = [[]]\n",
    "    weight_idx = 1\n",
    "\n",
    "    for layer in model_no_bn.layers:\n",
    "        if layer is model_no_bn.layers[-1]:\n",
    "            out_weights.append(np.array(in_weights[weight_idx]))\n",
    "            continue\n",
    "\n",
    "        if \"Conv2D\" in str(layer):\n",
    "            weight = in_weights[weight_idx][0]\n",
    "            bn_weights = in_weights[weight_idx + 1]\n",
    "            for i in range(len(weight)):\n",
    "                for j in range(len(weight[i])):\n",
    "                    for k in range(len(weight[i][j])):\n",
    "                        for l in range(len(weight[i][j][k])):\n",
    "                            weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][k] / np.sqrt(bn_weights[3][k])\n",
    "\n",
    "            c = len(weight[0][0])\n",
    "            bias = [0.0] * c\n",
    "            for i in range(c):\n",
    "                bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "            weight_idx += 2\n",
    "            out_weights.append([np.array(weight), np.array(bias)])\n",
    "    \n",
    "    return out_weights\n",
    "\n",
    "def load_model_no_bn(weights_list, model_no_bn):\n",
    "    epsilon = 0.0001\n",
    "    model_no_bn.build(input_shape=(1,160,320,3))\n",
    "    weight_idx = 1\n",
    "    for layer in model_no_bn.layers:\n",
    "        if layer is model_no_bn.layers[-1]:\n",
    "            layer.set_weights(np.array(weights_list[weight_idx]))\n",
    "            continue\n",
    "\n",
    "        if \"DepthwiseConv2D\" in str(layer):\n",
    "            weight = weights_list[weight_idx][0]\n",
    "            bn_weights = weights_list[weight_idx + 1]\n",
    "            for i in range(len(weight)):\n",
    "                for j in range(len(weight[0])):\n",
    "                    for k in range(len(weight[0][0])):\n",
    "                        for l in range(len(weight[0][0][0])):\n",
    "                            weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][k] / np.sqrt(bn_weights[3][k])\n",
    "\n",
    "            c = len(weight[0][0])\n",
    "            bias = [0.0] * c\n",
    "            for i in range(c):\n",
    "                bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "            weight_idx += 2\n",
    "\n",
    "            layer.set_weights([np.array(weight), np.array(bias)])\n",
    "\n",
    "        elif \"Conv2D\" in str(layer):\n",
    "            weight = weights_list[weight_idx][0]\n",
    "            bn_weights = weights_list[weight_idx + 1]\n",
    "            for i in range(len(weight)):\n",
    "                for j in range(len(weight[0])):\n",
    "                    for k in range(len(weight[0][0])):\n",
    "                        for l in range(len(weight[0][0][0])):\n",
    "                            weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][l] / np.sqrt(bn_weights[3][l])\n",
    "\n",
    "            c = len(weight[0][0][0])\n",
    "            bias = [0.0] * c\n",
    "            for i in range(c):\n",
    "                bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "            weight_idx += 2\n",
    "\n",
    "            layer.set_weights([np.array(weight), np.array(bias)])\n",
    "\n",
    "'''\n",
    "You should report the average IoU for each quantized model you get\n",
    "'''\n",
    "def do_inference(model):\n",
    "    avg_iou = 0\n",
    "    import json\n",
    "    with open('groundtruth.txt', 'r') as outfile:\n",
    "        lines = json.load(outfile)\n",
    "        for line in lines[:100]:\n",
    "            input_img = load_input(line[0])\n",
    "            output = model.predict(input_img).transpose(0,3,1,2)\n",
    "            avg_iou+= bbox_iou(get_box(output),line[1])\n",
    "        avg_iou = avg_iou/len(lines[:100])\n",
    "        return avg_iou\n",
    "    \n",
    "\n",
    "'''\n",
    "Now finish the function to compute the iou between two given box.\n",
    "\n",
    "You can refer to the website: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "'''\n",
    "# box := (x, y, delta x, delta y)\n",
    "def bbox_iou(boxA, boxB):\n",
    "    '''your code here'''\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    boxA[2] += boxA[0]\n",
    "    boxA[3] += boxA[1]\n",
    "    boxB[2] += boxB[0]\n",
    "    boxB[3] += boxB[1]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "'''\n",
    "This is the function to get the predict box (x,y,w,h)\n",
    "'''\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def get_box(output):\n",
    "    anchors = [1.4940052559648322, 2.3598481287086823, 4.0113013115312155, 5.760873975661669]\n",
    "    h = output.shape[2]\n",
    "    w = output.shape[3]\n",
    "    output = output.reshape(2,5,800).transpose(1,0,2).flatten().reshape(5,1600)\n",
    "    grid_x = np.tile(np.tile(np.linspace(0,w-1,w),h).reshape(h,w),(2,1,1)).flatten()\n",
    "    grid_y =np.tile(np.tile(np.linspace(0,h-1,h),w).reshape(w,h).T,(2,1,1)).flatten()\n",
    "    xs = sigmoid(output[0]) + grid_x\n",
    "    ys = sigmoid(output[1]) + grid_y\n",
    "    anchor_w = np.zeros(1600)\n",
    "    anchor_h = np.zeros(1600)\n",
    "    anchor_w[0:800] = anchors[0]\n",
    "    anchor_w[800:1600] = anchors[2]\n",
    "    anchor_h[0:800] = anchors[1]\n",
    "    anchor_h[800:1600] = anchors[3]\n",
    "    ws = np.exp(output[2]) * anchor_w\n",
    "    hs = np.exp(output[3]) * anchor_h\n",
    "    ind = np.argmax(output[4])\n",
    "    bcx = xs[ind]\n",
    "    bcy = ys[ind]\n",
    "    bw = ws[ind]\n",
    "    bh = hs[ind]\n",
    "    box = [bcx/w, bcy/h, bw/w, bh/h]\n",
    "    return box\n",
    "'''\n",
    "The function is to convert the image into the input type.\n",
    "'''\n",
    "def load_input(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((320,160))\n",
    "    input_img = np.asarray(img).astype(np.float32)\n",
    "    input_img = (input_img/255 - 0.5)/0.25\n",
    "    return input_img[np.newaxis,:]\n",
    "\n",
    "'''\n",
    "write down your code to load the model\n",
    "'''\n",
    "def load_model(weights, in_model):\n",
    "    layer_list = [(\"ReLU\" not in ls) and (\"MaxPooling\" not in ls) for ls in map(str, in_model.layers)]\n",
    "    #for l in model.layers:\n",
    "    #    print(l)\n",
    "    in_model.build([1,160,320,3])\n",
    "    #print(type(model.layers[0]))\n",
    "    #print(model.layers[0].get_weights())\n",
    "    #print(model.layers[0].count_params())\n",
    "    #for d in dir(model.layers[0]):\n",
    "    #    print(d)\n",
    "    weight_idx = 1\n",
    "    for idx, val in enumerate(layer_list):\n",
    "        if val == False:\n",
    "            continue\n",
    "        #print(in_model.layers[idx].input_shape())\n",
    "        in_model.layers[idx].set_weights(weights[weight_idx])\n",
    "        weight_idx += 1\n",
    "'''\n",
    "Based on the model_no_bn quantize the weights to 16 bits, 8 bits respectively.\n",
    "\n",
    "The requirement of quantization is given below:\n",
    "\n",
    "* For each layer's weights, set the upper bound as the minimum 2^n which is larger than the maximum value of unsigned weights. (eg: if the maximum value is 4.2375 and the minimum value is -7.83421, then the upper bound is 2^3 = 8)\n",
    "\n",
    "* Note that for each layer, the distribution of weights could be different.\n",
    "\n",
    "* The sign takes one bit. For example, if the upper bound is 8 and 5 bits is given for floating part, it actually takes 9 bits.\n",
    "\n",
    "* Do not quantize the bias!\n",
    "\n",
    "and get the accuracy report\n",
    "'''\n",
    "def quantize_layer(weights, nbits):\n",
    "    for w in weights:\n",
    "        assert(type(w) != type([]))\n",
    "\n",
    "    abs_max = np.max(np.abs(weights))\n",
    "    sign_bits = 1\n",
    "    exp_bits = 0\n",
    "    while float(2**exp_bits) < abs_max:\n",
    "        exp_bits += 1\n",
    "    exp_bits = min(exp_bits, nbits-1)\n",
    "    mantissa_bits = nbits - sign_bits - exp_bits\n",
    "    \n",
    "    \n",
    "    #print(sign_bits, exp_bits, mantissa_bits)\n",
    "    def callback(w):\n",
    "        abs_w = abs(w)\n",
    "        int_w = np.floor(abs_w)\n",
    "        rem_w = abs_w - int_w\n",
    "        #print(abs_w, int_w, rem_w)\n",
    "        #print(2**(-mantissa_bits))\n",
    "        float_w = np.round(rem_w / (2**(-mantissa_bits)))\n",
    "        \n",
    "        return np.sign(w) * (int_w + float_w*2**(-mantissa_bits))\n",
    "    \n",
    "    if \"ndarray\" in str(type(weights)):\n",
    "        return np.array(map(callback, weights))\n",
    "    return [callback(w) for w in weights]\n",
    "\n",
    "def quantize_model_raw(weights, nbits):    \n",
    "    for idx, wlist in enumerate(weights):\n",
    "        if len(wlist) == 0:\n",
    "            continue\n",
    "        if type(wlist[0]) == type([]):\n",
    "            wlist = quantize_model(wlist)\n",
    "        else:\n",
    "            weights[idx] = quantize_layer(wlist, nbits)        \n",
    "    return weights\n",
    "\n",
    "\n",
    "def quantize_model(model, nbits):\n",
    "    for layer in model.layers:\n",
    "        if \"Conv\" not in str(layer):\n",
    "            continue\n",
    "        new_weights = [quantize_layer(m, 16) for m in layer.get_weights()]\n",
    "        layer.set_weights(new_weights)\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8883778467774391, 0.677718210220337, 0.02215129253462269, 0.05548492466000003]\n"
     ]
    }
   ],
   "source": [
    "input_img = load_input('images/2.jpg')\n",
    "mnb = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb)\n",
    "output = mnb.predict(input_img).transpose(0,3,1,2)\n",
    "print(get_box(output))\n",
    "mnb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8880645155906677, 0.6772263944149017, 0.021240140941964566, 0.05858664254991809]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the cell to test your weights correctness.\n",
    "\n",
    "The output should be :\n",
    "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "m = model()\n",
    "load_model(getParams(), model)\n",
    "output = m.predict(input_img).transpose(0,3,1,2)\n",
    "print (get_box(output))\n",
    "m = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6385218143190471\n",
      "0.6394115229971922\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The iou should be about 67%\n",
    "'''\n",
    "mnb = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb)\n",
    "m = model()\n",
    "load_model(getParams(), m)\n",
    "print(do_inference(m))\n",
    "print(do_inference(mnb))\n",
    "m = None\n",
    "mnb = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 2\n",
    "In this section, you need to convert the model into a model without batch normalization layers. The output of two model should be the same. Then you are required to quantize the model without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 8 quantized floats:\n",
      "\tBN: 0.0179927511512\n",
      "\tNo BN: 0.228429010723\n",
      "With 16 quantized floats:\n",
      "\tBN: 0.638026550186\n",
      "\tNo BN: 0.228429010723\n",
      "With 24 quantized floats:\n",
      "\tBN: 0.638512162397\n",
      "\tNo BN: 0.228429010723\n",
      "With 32 quantized floats:\n",
      "\tBN: 0.638521796586\n",
      "\tNo BN: 0.228429010723\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Based on the model_no_bn\n",
    "\n",
    "Now you can quantize both weights and bias parts.\n",
    "\n",
    "Explore eight different combination of weights and parts and specify your methods' details, and get the accuracy report\n",
    "'''\n",
    "for nbits in [8, 16, 24, 32]:\n",
    "    load_model(quantize_model_raw(getParams(), nbits), model)\n",
    "    bn = do_inference(model)\n",
    "    load_model_no_bn(getParams())\n",
    "    quantize_model(model_no_bn, nbits)\n",
    "    \n",
    "    no_bn = do_inference(model_no_bn)\n",
    "    print(\"With {nbits} quantized floats:\\n\\tBN: {bn}\\n\\tNo BN: {no_bn}\".format(\n",
    "            nbits=nbits, bn=bn, no_bn=no_bn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
