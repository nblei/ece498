{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image, ImageDraw\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1\n",
    "firstly, a list which contains weights is given. You need to load the weight into the model correctly. Then test the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Weights_list is the parameter sets of the networks\n",
    "\n",
    "It's structure is like:\n",
    "[\n",
    "[],\n",
    "[layer a's weights, layer a's bias,...],\n",
    "[layer b's weights]\n",
    "]\n",
    "'''\n",
    "import pickle\n",
    "\n",
    "    \n",
    "def getParams():\n",
    "    with open('params_sets', 'rb') as fp:\n",
    "        weights_list = pickle.load(fp)\n",
    "    weights_list = [np.array(w) for w in weights_list]\n",
    "    return weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is the model for the testing part\n",
    "names = ['dw1', 'bn1', 'conv1', 'bn2', 'dw2', 'bn3', 'conv2', 'bn4', 'dw3', 'bn5', 'dw4', 'bn6', 'conv3', 'bn7',\n",
    "        'dw5', 'bn8', 'dw6', 'bn9', 'conv4', 'bn10', 'conv5']\n",
    "def model():\n",
    "    rv = tf.keras.models.Sequential(\n",
    "        [\n",
    "        #first dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(48,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #second dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(96,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #third dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(192,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #fourth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(384,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #fifth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(512,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        layers.BatchNormalization(momentum=0.1,\n",
    "        epsilon=1e-5,trainable=False),\n",
    "        layers.ReLU(4.0),\n",
    "        #output\n",
    "        layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        ]\n",
    "    )\n",
    "    rv.trainable = False\n",
    "    return rv\n",
    "\n",
    "def model_no_bn():\n",
    "    rv = tf.keras.models.Sequential(\n",
    "        [\n",
    "        #first dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(48,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #second dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(96,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #third dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(192,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #maxpooling\n",
    "        layers.MaxPool2D(strides =(2,2)),\n",
    "        #fourth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(384,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #fifth dw module\n",
    "        layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "        layers.ReLU(4.0),\n",
    "        layers.Conv2D(512,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "        layers.ReLU(4.0),\n",
    "        #output\n",
    "        layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "        ]\n",
    "    )\n",
    "    rv.trainable = False\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write down the code to absorb bn layer into conv layer and maintain the same output as the original model. (please refer to HW2 Q4)\n",
    "'''\n",
    "def load_model_no_bn(weights_list, model_no_bn):\n",
    "    model_no_bn.build(input_shape=(1,160,320,3))\n",
    "    weight_idx = 1\n",
    "    for layer in model_no_bn.layers:\n",
    "        if layer is model_no_bn.layers[-1]:\n",
    "            layer.set_weights(np.array(weights_list[weight_idx]))\n",
    "            continue\n",
    "\n",
    "        if \"DepthwiseConv2D\" in str(layer):\n",
    "            weight = weights_list[weight_idx][0]\n",
    "            bn_weights = weights_list[weight_idx + 1]\n",
    "            for i in range(len(weight)):\n",
    "                for j in range(len(weight[0])):\n",
    "                    for k in range(len(weight[0][0])):\n",
    "                        for l in range(len(weight[0][0][0])):\n",
    "                            weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][k] / np.sqrt(bn_weights[3][k])\n",
    "\n",
    "            c = len(weight[0][0])\n",
    "            bias = [0.0] * c\n",
    "            for i in range(c):\n",
    "                bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "            weight_idx += 2\n",
    "\n",
    "            layer.set_weights([np.array(weight), np.array(bias)])\n",
    "\n",
    "        elif \"Conv2D\" in str(layer):\n",
    "            weight = weights_list[weight_idx][0]\n",
    "            bn_weights = weights_list[weight_idx + 1]\n",
    "            for i in range(len(weight)):\n",
    "                for j in range(len(weight[0])):\n",
    "                    for k in range(len(weight[0][0])):\n",
    "                        for l in range(len(weight[0][0][0])):\n",
    "                            weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][l] / np.sqrt(bn_weights[3][l])\n",
    "\n",
    "            c = len(weight[0][0][0])\n",
    "            bias = [0.0] * c\n",
    "            for i in range(c):\n",
    "                bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "            weight_idx += 2\n",
    "\n",
    "            layer.set_weights([np.array(weight), np.array(bias)])\n",
    "\n",
    "'''\n",
    "You should report the average IoU for each quantized model you get\n",
    "'''\n",
    "def do_inference(model):\n",
    "    avg_iou = 0\n",
    "    import json\n",
    "    with open('groundtruth.txt', 'r') as outfile:\n",
    "        lines = json.load(outfile)\n",
    "        for line in lines[:100]:\n",
    "            input_img = load_input(line[0])\n",
    "            output = model.predict(input_img).transpose(0,3,1,2)\n",
    "            avg_iou+= bbox_iou(get_box(output),line[1])\n",
    "        avg_iou = avg_iou/len(lines[:100])\n",
    "        return avg_iou\n",
    "    \n",
    "\n",
    "'''\n",
    "Now finish the function to compute the iou between two given box.\n",
    "\n",
    "You can refer to the website: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "'''\n",
    "# box := (x, y, delta x, delta y)\n",
    "def bbox_iou(boxA, boxB):\n",
    "    '''your code here'''\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    boxA[2] += boxA[0]\n",
    "    boxA[3] += boxA[1]\n",
    "    boxB[2] += boxB[0]\n",
    "    boxB[3] += boxB[1]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou\n",
    "'''\n",
    "This is the function to get the predict box (x,y,w,h)\n",
    "'''\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def get_box(output):\n",
    "    anchors = [1.4940052559648322, 2.3598481287086823, 4.0113013115312155, 5.760873975661669]\n",
    "    h = output.shape[2]\n",
    "    w = output.shape[3]\n",
    "    output = output.reshape(2,5,800).transpose(1,0,2).flatten().reshape(5,1600)\n",
    "    grid_x = np.tile(np.tile(np.linspace(0,w-1,w),h).reshape(h,w),(2,1,1)).flatten()\n",
    "    grid_y =np.tile(np.tile(np.linspace(0,h-1,h),w).reshape(w,h).T,(2,1,1)).flatten()\n",
    "    xs = sigmoid(output[0]) + grid_x\n",
    "    ys = sigmoid(output[1]) + grid_y\n",
    "    anchor_w = np.zeros(1600)\n",
    "    anchor_h = np.zeros(1600)\n",
    "    anchor_w[0:800] = anchors[0]\n",
    "    anchor_w[800:1600] = anchors[2]\n",
    "    anchor_h[0:800] = anchors[1]\n",
    "    anchor_h[800:1600] = anchors[3]\n",
    "    ws = np.exp(output[2]) * anchor_w\n",
    "    hs = np.exp(output[3]) * anchor_h\n",
    "    ind = np.argmax(output[4])\n",
    "    bcx = xs[ind]\n",
    "    bcy = ys[ind]\n",
    "    bw = ws[ind]\n",
    "    bh = hs[ind]\n",
    "    box = [bcx/w, bcy/h, bw/w, bh/h]\n",
    "    return box\n",
    "'''\n",
    "The function is to convert the image into the input type.\n",
    "'''\n",
    "def load_input(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((320,160))\n",
    "    input_img = np.asarray(img).astype(np.float32)\n",
    "    input_img = (input_img/255 - 0.5)/0.25\n",
    "    return input_img[np.newaxis,:]\n",
    "\n",
    "'''\n",
    "write down your code to load the model\n",
    "'''\n",
    "def load_model(weights, in_model):\n",
    "    layer_list = [(\"ReLU\" not in ls) and (\"MaxPooling\" not in ls) for ls in map(str, in_model.layers)]\n",
    "    in_model.build([1,160,320,3])\n",
    "    weight_idx = 1\n",
    "    for idx, val in enumerate(layer_list):\n",
    "        if val == False:\n",
    "            continue\n",
    "        in_model.layers[idx].set_weights(weights[weight_idx])\n",
    "        weight_idx += 1\n",
    "\n",
    "'''\n",
    "Based on the model_no_bn quantize the weights to 16 bits, 8 bits respectively.\n",
    "\n",
    "The requirement of quantization is given below:\n",
    "\n",
    "* For each layer's weights, set the upper bound as the minimum 2^n which is larger than the maximum value of unsigned weights. (eg: if the maximum value is 4.2375 and the minimum value is -7.83421, then the upper bound is 2^3 = 8)\n",
    "\n",
    "* Note that for each layer, the distribution of weights could be different.\n",
    "\n",
    "* The sign takes one bit. For example, if the upper bound is 8 and 5 bits is given for floating part, it actually takes 9 bits.\n",
    "\n",
    "* Do not quantize the bias!\n",
    "\n",
    "and get the accuracy report\n",
    "'''\n",
    "import math\n",
    "def quantize_layer(weights, nbits):\n",
    "    for w in weights:\n",
    "        assert(type(w) != type([]))\n",
    "\n",
    "    abs_max = np.max(np.abs(weights))\n",
    "    sign_bits = 1\n",
    "    exp_bits = None\n",
    "    exp = 0\n",
    "    exp = np.max([np.ceil(np.log2(abs_max)), 0])\n",
    "    #print(\"Largest exp is {exp}\".format(exp=exp))\n",
    "    if exp == 0:\n",
    "        exp_bits = 0\n",
    "    else:\n",
    "        exp_bits = np.ceil(np.log2(exp))\n",
    "    if (exp_bits > nbits-1):\n",
    "        print(\"Warning, {exp_bits} of {nbits} are used for exponent\".format(exp_bits=exp_bits,\n",
    "                                                                           nbits=nbits))\n",
    "        exp_bits = min(exp_bits, nbits-1)\n",
    "    mantissa_bits = nbits - sign_bits - exp_bits\n",
    "    #print(\"Number of exp bits: {exp_bits}\".format(exp_bits=exp_bits))\n",
    "    if (exp_bits > 8):\n",
    "        print(\"Exponent too big, abs max is {abs_max}\".format(abs_max=abs_max))\n",
    "    if (np.isnan(exp_bits) or np.isnan(mantissa_bits)):\n",
    "        print(\"Found NaNs: (abs_max, exp_bits, mantissa_bits) = ({am}, {eb}, {mb})\\n\".format(\n",
    "                            am=abs_max, eb=exp_bits, mb=mantissa_bits))\n",
    "    \n",
    "    #print(sign_bits, exp_bits, mantissa_bits)\n",
    "    def callback(w):\n",
    "        assert(\"list\" not in str(type(w)))\n",
    "        abs_w = abs(w)\n",
    "        # mantissa evenly divides the half-open range [2**exp, 2**(exp+1))\n",
    "        exp = np.floor(np.log2(abs_w))\n",
    "        w_exp = 2.0**exp\n",
    "        mantissa_interval = 2.0**exp / (2.0**mantissa_bits)\n",
    "        w_mant = abs_w - w_exp\n",
    "        w_mant = (mantissa_interval) * np.round(w_mant / mantissa_interval)\n",
    "        rv = (w_exp + w_mant) * np.sign(w)\n",
    "        #print(rv)\n",
    "        if np.isnan(rv).any():\n",
    "            print(\"Found nan {w}: exp_bits: {eb}, mantissa_bits: {mb}\".format(\n",
    "            w=w, eb=exp_bits, mb=mantissa_bits))\n",
    "        return rv\n",
    "        \n",
    "    if \"ndarray\" in str(type(weights)):\n",
    "        return np.array(map(callback, weights))\n",
    "    else:\n",
    "        print(\"Expected numpy array\")\n",
    "        return None\n",
    "    #return [callback(w) for w in weights]\n",
    "\n",
    "def quantize_model_raw(weights, nbits):    \n",
    "    for idx, wlist in enumerate(weights):\n",
    "        if len(wlist) == 0:\n",
    "            continue\n",
    "        if type(wlist[0]) == type([]):\n",
    "            wlist = quantize_model(wlist)\n",
    "        else:\n",
    "            weights[idx] = quantize_layer(wlist, nbits)        \n",
    "    return weights\n",
    "\n",
    "\n",
    "def quantize_model(model, nbits):\n",
    "    for layer in model.layers:\n",
    "        if \"Conv\" not in str(layer):\n",
    "            continue\n",
    "        new_weights = [quantize_layer(m, nbits) for m in layer.get_weights()]\n",
    "        layer.set_weights(new_weights)\n",
    "    return model, new_weights\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.2    2.1   -0.23   1.242]\n",
      "[-0.234375  0.75    ]\n"
     ]
    }
   ],
   "source": [
    "n = np.array([1.2, 2.1, -0.23, 1.242])\n",
    "print(quantize_layer(n, 32))\n",
    "n = np.array([-0.23, 0.75])\n",
    "print(quantize_layer(n, 4))\n",
    "m = model()\n",
    "load_model(getParams(), m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tensorflow.python.keras.engine.sequential.Sequential at 0x7f9eac702490>,\n",
       " [array([[[[-0.02560806,  0.00185621,  0.02195549, ..., -0.00584257,\n",
       "             0.00628638, -0.36338806],\n",
       "           [-0.01747561,  0.02075624, -0.00821996, ..., -0.00965595,\n",
       "             0.00861645, -0.04374599],\n",
       "           [ 0.01971388,  0.00125912, -0.03931427, ..., -0.05925083,\n",
       "             0.07988739, -0.01765728],\n",
       "           ...,\n",
       "           [-0.0065037 , -0.03998756, -0.05000877, ...,  0.015347  ,\n",
       "            -0.01759577, -0.11148834],\n",
       "           [-0.01250672,  0.01442003,  0.04115009, ..., -0.00356311,\n",
       "            -0.06481743,  0.1586647 ],\n",
       "           [ 0.00347739,  0.02072859,  0.04285908, ..., -0.02249575,\n",
       "             0.01962471,  0.0037328 ]]]], dtype=float32)])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantize_model(m, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb2)\n",
    "mnb2, _ = quantize_model(mnb2, 32)\n",
    "mnb1 = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f9edd358490>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd358690>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd358350>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd358810>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f9edd358850>\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f9edd3588d0>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd358a10>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd358990>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd358b90>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f9edd358bd0>\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f9edd358c50>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd358d10>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd358290>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd282d50>\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f9edd282fd0>\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f9edd282950>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd2911d0>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd291150>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd291390>\n",
      "<tensorflow.python.keras.layers.convolutional.DepthwiseConv2D object at 0x7f9edd291310>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd291610>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd291490>\n",
      "0.0\n",
      "0.0\n",
      "<tensorflow.python.keras.layers.advanced_activations.ReLU object at 0x7f9edd291790>\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f9edd2917d0>\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "#mnb1 = model_no_bn()\n",
    "#mnb2 = model_no_bn()\n",
    "#load_model_no_bn(getParams(), mnb1)\n",
    "#load_model_no_bn(getParams(), mnb2)\n",
    "#_, w1 = quantize_model(mnb1, 8)\n",
    "#mnb2, _ = quantize_model(mnb2, 32)\n",
    "\n",
    "for idx in range(len(mnb2.layers)):\n",
    "    print(mnb2.layers[idx])\n",
    "    for widx in range(len(mnb2.layers[idx].get_weights())):\n",
    "        print(np.mean(np.abs(mnb2.layers[idx].get_weights()[widx] - mnb1.layers[idx].get_weights()[widx])))\n",
    "\n",
    "#w1 = None\n",
    "#w2 = None\n",
    "#del mnb1\n",
    "#del mnb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nathan/.virtualenvs/tfPy2/local/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "mnb = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb)\n",
    "m = model()\n",
    "load_model(getParams(), m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "drawBox() takes exactly 3 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d5243ddc388c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.8880645155906677\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6772263944149017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02124013871572325\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.058586649582813566\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdrawBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m#mnb = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: drawBox() takes exactly 3 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "def drawBox(image_path, bbox, write_path):\n",
    "    WIDTH=640.0\n",
    "    HEIGHT=360.0\n",
    "    src_img = Image.open(image_path)\n",
    "    coords = (((bbox[0]-bbox[2]/2)*WIDTH, (bbox[1]-bbox[3]/2)*HEIGHT), ((bbox[0]+bbox[2]/2)*WIDTH, (bbox[1]+bbox[3]/2)*HEIGHT))\n",
    "    draw = ImageDraw.Draw(src_img)\n",
    "    draw.rectangle(coords)\n",
    "    src_img.save(write_path)\n",
    "    \n",
    "img_path = 'images/2.jpg'\n",
    "input_img = load_input(img_path)\n",
    "#output = m.predict(input_img).transpose(0,3,1,2)\n",
    "#bbox = get_box(output)\n",
    "bbox = [0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "print(bbox)\n",
    "drawBox(img_path, bbox)\n",
    "#mnb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8880645155906677, 0.6772263944149017, 0.021240140941964566, 0.05858664254991809]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This is the cell to test your weights correctness.\n",
    "\n",
    "The output should be :\n",
    "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "m = model()\n",
    "load_model(getParams(), m)\n",
    "output = m.predict(input_img).transpose(0,3,1,2)\n",
    "print (get_box(output))\n",
    "m = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6385218143190471\n",
      "0.6394115229971922\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The iou should be about 67%\n",
    "'''\n",
    "mnb = model_no_bn()\n",
    "load_model_no_bn(getParams(), mnb)\n",
    "m = model()\n",
    "load_model(getParams(), m)\n",
    "print(do_inference(m))\n",
    "print(do_inference(mnb))\n",
    "m = None\n",
    "mnb = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 2\n",
    "In this section, you need to convert the model into a model without batch normalization layers. The output of two model should be the same. Then you are required to quantize the model without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 8 quantized floats:\n",
      "\tBN: 0.637164661016\n",
      "\tNo BN: 0.508875281964\n",
      "[0.888053260743618, 0.6771463364362716, 0.021262824114716566, 0.0588954534736361]\n",
      "[0.8868082776665688, 0.6787367999553681, 0.016961657995015356, 0.06047556574731]\n",
      "With 12 quantized floats:\n",
      "\tBN: 0.638487680878\n",
      "\tNo BN: 0.640184099694\n",
      "[0.888065131008625, 0.6772283524274826, 0.021239384019917686, 0.058580302394650285]\n",
      "[0.8882624104619026, 0.6777048885822297, 0.022280332159926867, 0.05455664927023237]\n",
      "With 16 quantized floats:\n",
      "\tBN: 0.638521388576\n",
      "\tNo BN: 0.637607516674\n",
      "[0.8880644798278808, 0.6772268295288086, 0.02124017878806691, 0.058587535727643004]\n",
      "[0.8883731961250305, 0.6777315616607666, 0.022121961805306012, 0.05542029586706213]\n",
      "With 20 quantized floats:\n",
      "\tBN: 0.638521851425\n",
      "\tNo BN: 0.639412643879\n",
      "[0.8880645155906677, 0.6772263914346695, 0.021240132036999308, 0.05858666013215678]\n",
      "[0.8883777961134911, 0.6777168184518814, 0.022150776046637757, 0.05548471367313588]\n",
      "With 24 quantized floats:\n",
      "\tBN: 0.638521814319\n",
      "\tNo BN: 0.639411547593\n",
      "[0.8880645155906677, 0.6772263944149017, 0.021240140941964566, 0.05858664254991809]\n",
      "[0.8883778423070907, 0.6777181029319763, 0.0221512012587288, 0.055484893011970404]\n",
      "With 28 quantized floats:\n",
      "\tBN: 0.638521814319\n",
      "\tNo BN: 0.639411528275\n",
      "[0.8880645155906677, 0.6772263944149017, 0.021240140941964566, 0.05858664254991809]\n",
      "[0.888377845287323, 0.6777182072401047, 0.022151285855898747, 0.0554849211435523]\n",
      "With 32 quantized floats:\n",
      "\tBN: 0.638521814319\n",
      "\tNo BN: 0.639411522997\n",
      "[0.8880645155906677, 0.6772263944149017, 0.021240140941964566, 0.05858664254991809]\n",
      "[0.8883778467774391, 0.677718210220337, 0.02215129253462269, 0.05548492466000003]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Based on the model_no_bn\n",
    "\n",
    "Now you can quantize both weights and bias parts.\n",
    "\n",
    "Explore eight different combination of weights and parts and specify your methods' details, and get the accuracy report\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "img_path = 'images/2.jpg'\n",
    "\n",
    "m = model()\n",
    "mnb = model_no_bn()\n",
    "for nbits in [8, 12, 16, 20, 24, 28, 32]:\n",
    "    load_model(getParams(), m)\n",
    "    quantize_model(m, nbits)\n",
    "    bn = do_inference(m)\n",
    "    load_model_no_bn(getParams(), mnb)\n",
    "    quantize_model(mnb, nbits)\n",
    "    no_bn = do_inference(mnb)\n",
    "    output = m.predict(input_img).transpose(0,3,1,2)\n",
    "    output_no_bn = mnb.predict(input_img).transpose(0,3,1,2)\n",
    "\n",
    "    print(\"With {nbits} quantized floats:\\n\\tBN: {bn}\\n\\tNo BN: {no_bn}\".format(\n",
    "            nbits=nbits, bn=bn, no_bn=no_bn))\n",
    "    print(get_box(output))\n",
    "    print(get_box(output_no_bn))\n",
    "    write_path = \"output/mnb_{nbits}.jpg\".format(nbits=str(nbits))\n",
    "    drawBox(img_path, get_box(output_no_bn), write_path)\n",
    "    write_path = \"output/m_{nbits}.jpg\".format(nbits=str(nbits))\n",
    "    drawBox(img_path, get_box(output), write_path)\n",
    "    \n",
    "    \n",
    "m = None\n",
    "mnb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
