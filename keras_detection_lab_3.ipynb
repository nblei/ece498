{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from PIL import Image\n",
    "print(tf.VERSION)\n",
    "print(tf.keras.__version__)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 1\n",
    "firstly, a list which contains weights is given. You need to load the weight into the model correctly. Then test the model on the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Weights_list is the parameter sets of the networks\n",
    "\n",
    "It's structure is like:\n",
    "[\n",
    "[],\n",
    "[layer a's weights, layer a's bias,...],\n",
    "[layer b's weights]\n",
    "]\n",
    "'''\n",
    "\n",
    "import pickle\n",
    "with open ('params_sets', 'rb') as fp:\n",
    "    weights_list = pickle.load(fp, encoding='latin1')\n",
    "    \n",
    "print(len(weights_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#this is the model for the testing part\n",
    "names = ['dw1', 'bn1', 'conv1', 'bn2', 'dw2', 'bn3', 'conv2', 'bn4', 'dw3', 'bn5', 'dw4', 'bn6', 'conv3', 'bn7',\n",
    "        'dw5', 'bn8', 'dw6', 'bn9', 'conv4', 'bn10', 'conv5']\n",
    "model = tf.keras.models.Sequential(\n",
    "    [\n",
    "    #first dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(48,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #second dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(96,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #third dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(192,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #fourth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(384,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #fifth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=False),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(512,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    layers.BatchNormalization(momentum=0.1,\n",
    "    epsilon=1e-5,trainable=False),\n",
    "    layers.ReLU(4.0),\n",
    "    #output\n",
    "    layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "write down your code to load the model\n",
    "'''\n",
    "layer_list = [(\"ReLU\" not in ls) and (\"MaxPooling\" not in ls) for ls in map(str, model.layers)]\n",
    "#for l in model.layers:\n",
    "#    print(l)\n",
    "#model.build([1,160,320,3])\n",
    "#print(type(model.layers[0]))\n",
    "#print(model.layers[0].get_weights())\n",
    "#print(model.layers[0].count_params())\n",
    "#for d in dir(model.layers[0]):\n",
    "#    print(d)\n",
    "weight_idx = 1\n",
    "for idx, val in enumerate(layer_list):\n",
    "    if val == False:\n",
    "        continue\n",
    "    model.layers[idx].set_weights(np.array(weights_list[weight_idx]))\n",
    "    weight_idx += 1\n",
    "        \n",
    "\n",
    "#for n in dir(model):\n",
    "#    print(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The function is to convert the image into the input type.\n",
    "'''\n",
    "def load_input(path):\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((320,160))\n",
    "    input_img = np.asarray(img).astype(np.float32)\n",
    "    input_img = (input_img/255 - 0.5)/0.25\n",
    "    return input_img[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the function to get the predict box (x,y,w,h)\n",
    "'''\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "def get_box(output):\n",
    "    anchors = [1.4940052559648322, 2.3598481287086823, 4.0113013115312155, 5.760873975661669]\n",
    "    h = output.shape[2]\n",
    "    w = output.shape[3]\n",
    "    output = output.reshape(2,5,800).transpose(1,0,2).flatten().reshape(5,1600)\n",
    "    grid_x = np.tile(np.tile(np.linspace(0,w-1,w),h).reshape(h,w),(2,1,1)).flatten()\n",
    "    grid_y =np.tile(np.tile(np.linspace(0,h-1,h),w).reshape(w,h).T,(2,1,1)).flatten()\n",
    "    xs = sigmoid(output[0]) + grid_x\n",
    "    ys = sigmoid(output[1]) + grid_y\n",
    "    anchor_w = np.zeros(1600)\n",
    "    anchor_h = np.zeros(1600)\n",
    "    anchor_w[0:800] = anchors[0]\n",
    "    anchor_w[800:1600] = anchors[2]\n",
    "    anchor_h[0:800] = anchors[1]\n",
    "    anchor_h[800:1600] = anchors[3]\n",
    "    ws = np.exp(output[2]) * anchor_w\n",
    "    hs = np.exp(output[3]) * anchor_h\n",
    "    ind = np.argmax(output[4])\n",
    "    bcx = xs[ind]\n",
    "    bcy = ys[ind]\n",
    "    bw = ws[ind]\n",
    "    bh = hs[ind]\n",
    "    box = [bcx/w, bcy/h, bw/w, bh/h]\n",
    "    return box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the cell to test your weights correctness.\n",
    "\n",
    "The output should be :\n",
    "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "output = model.predict(input_img).transpose(0,3,1,2)\n",
    "print (get_box(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Now finish the function to compute the iou between two given box.\n",
    "\n",
    "You can refer to the website: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/\n",
    "\n",
    "'''\n",
    "# box := (x, y, delta x, delta y)\n",
    "def bbox_iou(boxA, boxB):\n",
    "    '''your code here'''\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    boxA[2] += boxA[0]\n",
    "    boxA[3] += boxA[1]\n",
    "    boxB[2] += boxB[0]\n",
    "    boxB[3] += boxB[1]\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Given dataset compute the iou\n",
    "'''\n",
    "import json\n",
    "with open('groundtruth.txt', 'r') as outfile:\n",
    "    lines = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The iou should be about 67%\n",
    "'''\n",
    "avg_iou = 0\n",
    "print(len(lines))\n",
    "for line in lines:\n",
    "    input_img = load_input(line[0])\n",
    "    output = model.predict(input_img).transpose(0,3,1,2)\n",
    "    avg_iou+= bbox_iou(get_box(output),line[1])\n",
    "avg_iou = avg_iou/1000\n",
    "print (avg_iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## section 2\n",
    "In this section, you need to convert the model into a model without batch normalization layers. The output of two model should be the same. Then you are required to quantize the model without batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_no_bn = tf.keras.models.Sequential(\n",
    "    [\n",
    "    #first dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(48,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #second dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(96,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #third dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(192,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #maxpooling\n",
    "    layers.MaxPool2D(strides =(2,2)),\n",
    "    #fourth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(384,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #fifth dw module\n",
    "    layers.DepthwiseConv2D((3, 3),padding='same',depth_multiplier=1,strides=(1,1),use_bias=True),\n",
    "    layers.ReLU(4.0),\n",
    "    layers.Conv2D(512,(1,1), padding='same',use_bias=True,strides=(1, 1)),\n",
    "    layers.ReLU(4.0),\n",
    "    #output\n",
    "    layers.Conv2D(10,(1,1), padding='same',use_bias=False,strides=(1, 1)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Write down the code to absorb bn layer into conv layer and maintain the same output as the original model. (please refer to HW2 Q4)\n",
    "'''\n",
    "model_no_bn.build(input_shape=(1,160,320,3))\n",
    "weight_idx = 1\n",
    "for layer in model_no_bn.layers:\n",
    "    print(layer)\n",
    "    print(weight_idx)\n",
    "    \n",
    "    if layer is model_no_bn.layers[-1]:\n",
    "        layer.set_weights(np.array(weights_list[weight_idx]))\n",
    "        continue\n",
    "    \n",
    "    if \"DepthwiseConv2D\" in str(layer):\n",
    "        weight = weights_list[weight_idx][0]\n",
    "        bn_weights = weights_list[weight_idx + 1]\n",
    "        for i in range(len(weight)):\n",
    "            for j in range(len(weight[0])):\n",
    "                for k in range(len(weight[0][0])):\n",
    "                    for l in range(len(weight[0][0][0])):\n",
    "                        weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][k] / np.sqrt(bn_weights[3][k])\n",
    "                        \n",
    "        c = len(weight[0][0])\n",
    "        bias = [0.0] * c\n",
    "        for i in range(c):\n",
    "            bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "        weight_idx += 2\n",
    "        \n",
    "        layer.set_weights([np.array(weight), np.array(bias)])\n",
    "    \n",
    "    elif \"Conv2D\" in str(layer):\n",
    "        weight = weights_list[weight_idx][0]\n",
    "        bn_weights = weights_list[weight_idx + 1]\n",
    "        for i in range(len(weight)):\n",
    "            for j in range(len(weight[0])):\n",
    "                for k in range(len(weight[0][0])):\n",
    "                    for l in range(len(weight[0][0][0])):\n",
    "                        weight[i][j][k][l] = weight[i][j][k][l] * bn_weights[0][l] / np.sqrt(bn_weights[3][l])\n",
    "                        \n",
    "        c = len(weight[0][0][0])\n",
    "        bias = [0.0] * c\n",
    "        for i in range(c):\n",
    "            bias[i] = bn_weights[0][i] * (0 - bn_weights[2][i]) / np.sqrt(bn_weights[3][i]) + bn_weights[1][i]\n",
    "        weight_idx += 2\n",
    "            \n",
    "        layer.set_weights([np.array(weight), np.array(bias)])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_no_bn.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This is the cell to test your weights correctness.\n",
    "\n",
    "The output should be :\n",
    "[0.8880645155906677, 0.6772263944149017, 0.02124013871572325, 0.058586649582813566]\n",
    "'''\n",
    "input_img = load_input('images/2.jpg')\n",
    "output = model_no_bn.predict(input_img).transpose(0,3,1,2)\n",
    "get_box(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on the model_no_bn quantize the weights to 16 bits, 8 bits respectively.\n",
    "\n",
    "The requirement of quantization is given below:\n",
    "\n",
    "* For each layer's weights, set the upper bound as the minimum 2^n which is larger than the maximum value of unsigned weights. (eg: if the maximum value is 4.2375 and the minimum value is -7.83421, then the upper bound is 2^3 = 8)\n",
    "\n",
    "* Note that for each layer, the distribution of weights could be different.\n",
    "\n",
    "* The sign takes one bit. For example, if the upper bound is 8 and 5 bits is given for floating part, it actually takes 9 bits.\n",
    "\n",
    "* Do not quantize the bias!\n",
    "\n",
    "and get the accuracy report\n",
    "'''\n",
    "def quantize_layer(weights, nbits):\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "You should report the average IoU for each quantized model you get\n",
    "'''\n",
    "avg_iou = 0\n",
    "for line in lines:\n",
    "    input_img = load_input(line[0])\n",
    "    output = model_no_bn.predict(input_img).transpose(0,3,1,2)\n",
    "    avg_iou+= bbox_iou(get_box(output),line[1])\n",
    "avg_iou = avg_iou/len(lines)\n",
    "print (avg_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Based on the model_no_bn\n",
    "\n",
    "Now you can quantize both weights and bias parts.\n",
    "\n",
    "Explore eight different combination of weights and parts and specify your methods' details, and get the accuracy report\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
